{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-08T17:57:20.490773Z","iopub.status.busy":"2024-06-08T17:57:20.490450Z","iopub.status.idle":"2024-06-08T17:57:21.472534Z","shell.execute_reply":"2024-06-08T17:57:21.471452Z","shell.execute_reply.started":"2024-06-08T17:57:20.490748Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # rawprocessing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'): \n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T17:57:55.701052Z","iopub.status.busy":"2024-06-08T17:57:55.700443Z","iopub.status.idle":"2024-06-08T17:57:55.770120Z","shell.execute_reply":"2024-06-08T17:57:55.769174Z","shell.execute_reply.started":"2024-06-08T17:57:55.701021Z"},"trusted":true},"outputs":[],"source":["# import requirement libraries and tools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.functional as F\n","# import plotly.graph_objects as go\n","\n","from tqdm.notebook import tqdm\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import TensorDataset, DataLoader\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from os.path import dirname, abspath\n","import sys, os\n","d = dirname(os.path.abspath(''))\n","sys.path.append(d)\n","# from implicitdl import ImplicitModel, ImplicitModelLoRA, ImplicitFunctionInf, ImplicitFunctionTriu, ImplicitRNNCell, ImplicitRNNCellLoRA\n","from implicitdl import ImplicitModel, ImplicitModelLoRA, ImplicitModelLoRA2, ImplicitFunctionInf, ImplicitFunctionTriu, ImplicitRNNCell, MyRNNCell, ImplicitRNNCellLoRA, SimpleRNN, LSTM, GRU"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T17:57:57.065625Z","iopub.status.busy":"2024-06-08T17:57:57.065167Z","iopub.status.idle":"2024-06-08T17:57:57.093775Z","shell.execute_reply":"2024-06-08T17:57:57.092332Z","shell.execute_reply.started":"2024-06-08T17:57:57.065592Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available\n"]}],"source":["is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda:3\") \n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Spiky region function\n","def spiky_function(x, scale=5, freq=[2, 23, 78, 100]):\n","    return scale * (np.sin(freq[0]*x) + np.sin(freq[1]*x) + np.sin(freq[2]*x) + np.sin(freq[3]*x))\n","\n","# Non-spiky region function with added noise\n","def non_spiky_function(x, noise_mean=0, noise_std=0.25):\n","    return np.sin(x) + np.random.normal(noise_mean, noise_std, size=x.shape)\n","\n","\n","generate=True\n","level = 7\n","if generate:\n","    # Parameters\n","    total_data_points = 10000\n","    num_spiky_regions = 20 + level\n","    spiky_region_size = 100 + level\n","    spiky_region_magnitude = level/2\n","\n","    # Generate data\n","    x_values = np.linspace(0, 100, total_data_points)\n","    y_values = np.zeros(total_data_points)\n","\n","    # Assign spiky regions\n","    spiky_regions = torch.randint(0, total_data_points - spiky_region_size, (num_spiky_regions, ))\n","    for start_idx in spiky_regions:\n","        end_idx = start_idx + spiky_region_size\n","        x_spiky = x_values[start_idx:end_idx]\n","        y_values[start_idx:end_idx] = spiky_function(x_spiky, spiky_region_magnitude)\n","        \n","    # Assign non-spiky regions\n","    mask = y_values == 0\n","\n","    y_values[mask] = non_spiky_function(x_values[mask], noise_mean=0, noise_std=level*0.05)\n","    # Plot the generated data\n","    if True:\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(y_values, label=\"Generated Data\")\n","        plt.title(f\"Generated Data with Spiky and Non-Spiky Regions -- level {level}\")\n","        plt.xlabel(\"x\")\n","        plt.ylabel(\"y\")\n","        plt.legend()\n","        plt.show()\n","    \n","    np.savetxt(f'./kaggle/input/spiky_data_{level}.csv', y_values, delimiter=',', fmt='%.17g')\n","\n","y_values = np.loadtxt(f'./kaggle/input/spiky_data_{level}.csv', delimiter=',')"]},{"cell_type":"markdown","metadata":{},"source":["# Data rescaling "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.06260131  0.12594226 -0.70494554 ... -1.10937081 -0.50981675\n"," -0.35796319]\n","[-0.00324502  0.01130713 -0.05282236 ... -0.08403667 -0.03776195\n"," -0.02604161]\n"]}],"source":["y_values.shape \n","print(y_values)\n","scaler = MinMaxScaler(feature_range=(-1, 1))\n","model=scaler.fit(y_values.reshape(-1,1))\n","y_values=model.transform(y_values.reshape(-1,1))\n","y_values=y_values.reshape(-1)\n","print(y_values)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# plt.figure(figsize=(12, 6))\n","# plt.plot(y_values, label=\"Generated Data\")\n","# plt.title(\"Rescaled Data with Spiky and Non-Spiky Regions\")\n","# plt.xlabel(\"x\")\n","# plt.ylabel(\"y\")\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Test and Train dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:00:47.270530Z","iopub.status.busy":"2024-06-08T18:00:47.270244Z","iopub.status.idle":"2024-06-08T18:00:47.286090Z","shell.execute_reply":"2024-06-08T18:00:47.285115Z","shell.execute_reply.started":"2024-06-08T18:00:47.270507Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train.shape =  (5964, 59, 1)\n","y_train.shape =  (5964, 1)\n","x_test.shape =  (3976, 59, 1)\n","y_test.shape =  (3976, 1)\n"]}],"source":["# function to create train, test data given stock data and sequence length\n","# we are predicting future so last portion of our data will be recorded as the test dataset example 50000 datapoints last 10k rakhlo future ka lia\n","def load_data(stock, look_back):\n","    # data_raw = stock.values # convert to numpy array\n","    data_raw = stock # convert to numpy array\n","    data = []\n","    \n","    # create all possible sequences of length look_back\n","    # we will take data example 0 to 60 then 1 to 61 then 2 to 62 ------ window size \n","    for index in range(len(data_raw) - look_back): \n","        data.append(data_raw[index:index + look_back])\n","    #print(data[0:3])\n","    data = np.array(data)\n","\n","    test_set_size = int(np.round(0.4*data.shape[0])) #30 percent for test\n","    train_set_size = data.shape[0] - (test_set_size)\n","    \n","    x_train = data[:train_set_size,:-1,:]\n","    y_train = data[:train_set_size,-1,:]\n","    \n","    x_test = data[train_set_size:,:-1]\n","    y_test = data[train_set_size:,-1,:]\n","    \n","    return [x_train, y_train, x_test, y_test]\n","\n","\n","look_back = 60 # choose sequence length # window size\n","# data_ = data[fea_name].values.reshape(-1,1)\n","data = y_values.reshape(-1,1)\n","x_train, y_train, x_test, y_test = load_data(data, look_back)\n","\n","print('x_train.shape = ',x_train.shape)\n","print('y_train.shape = ',y_train.shape)\n","print('x_test.shape = ',x_test.shape)\n","print('y_test.shape = ',y_test.shape)\n","# make training and test sets in torch\n","x_train = torch.from_numpy(x_train).type(torch.Tensor).to(device)\n","x_test = torch.from_numpy(x_test).type(torch.Tensor).to(device)\n","y_train = torch.from_numpy(y_train).type(torch.Tensor).to(device)\n","y_test = torch.from_numpy(y_test).type(torch.Tensor).to(device)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from typing import Optional\n","\n","class CustomInf(ImplicitFunctionInf):\n","    \"\"\"\n","    Change the default convergence parameters.\n","    \"\"\"\n","    mitr = grad_mitr = 500\n","    tol = grad_tol = 1e-6\n","    \n","def fuse_parameters(model):\n","    \"\"\"Move model parameters to a contiguous tensor, and return that tensor.\"\"\"\n","    n = sum(p.numel() for p in model.parameters())\n","    params = torch.zeros(n)\n","    i = 0\n","    for p in model.parameters():\n","        params_slice = params[i:i + p.numel()]\n","        params_slice.copy_(p.flatten())\n","        p.data = params_slice.view(p.shape)\n","        i += p.numel()\n","    return params\n","\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, hidden_size, output_dim, act):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(input_dim, hidden_size, bias=False),\n","            act(),\n","            nn.Linear(hidden_size, hidden_size, bias=False),\n","            act(),\n","            # nn.Linear(hidden_size, hidden_size, bias=False),\n","            # act(),\n","            nn.Linear(hidden_size, output_dim, bias=False),\n","        )\n","    def forward(self, x):\n","        x1 = x.flatten(1,-1)\n","        return self.model(x1)\n","    \n","# Here we define our model as a class\n","class OldVersionLSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bias=False)\n","        self.fc = nn.Linear(hidden_dim, output_dim, bias=False)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach())) #.detach() is a PyTorch method that creates a new tensor that does not require gradients. \n","        out = self.fc(out[:, -1, :])\n","        return out\n","    \n","class ImplicitRNN(nn.Module):\n","    def __init__(self, input_size, n, hidden_size, output_size, **kwargs):\n","        super().__init__()\n","        self.recurrent = ImplicitRNNCell(input_size, n, hidden_size, **kwargs)\n","        self.linear = nn.Linear(hidden_size, output_size)\n","        \n","    def forward(self, x):\n","        _, h = self.recurrent(x)\n","        return self.linear(h)\n","\n","class MyRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n","        super().__init__()\n","        self.recurrent = MyRNNCell(input_size, hidden_size, **kwargs)\n","        self.linear = nn.Linear(hidden_size, output_size)\n","        \n","    def forward(self, x):\n","        _, h = self.recurrent(x)\n","        return self.linear(h)\n","    \n","class ImplicitRNNLoRA(nn.Module):\n","    def __init__(self, lora_size, input_size, n, hidden_size, output_size, **kwargs):\n","        super().__init__()\n","        self.implicit = ImplicitRNNCellLoRA(lora_size, input_size, n, hidden_size, **kwargs)\n","        self.linear = nn.Linear(hidden_size, output_size)\n","        \n","    def forward(self, x):\n","        _, h = self.implicit(x)\n","        return self.linear(h)"]},{"cell_type":"markdown","metadata":{},"source":["# Define and train Model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","def train_model(model, x_train, y_train, optimiser, loss_fn, num_epochs=200, device=torch.device('cuda'), verbose=True):\n","    hist = np.zeros(num_epochs)\n","    for t in range(num_epochs):\n","        # print(model.par.device)\n","        y_train_pred = model(x_train)\n","        \n","        loss = loss_fn(y_train_pred, y_train)\n","        if t % 10 == 0 and verbose and t !=0:\n","            print(\"Epoch \", t, \"MSE: \", loss.item())\n","        hist[t] = loss.item()\n","\n","        optimiser.zero_grad()\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update parameters\n","        optimiser.step()\n","    return model, hist\n","\n","def plot_hist(hist):\n","    plt.figure()\n","    plt.plot(hist, label=\"Training loss\")\n","\n","from sklearn.metrics import r2_score, mean_absolute_percentage_error\n","\n","def evaluate_model(x_train, y_train, x_test, y_test, model):\n","    x_test = x_test.to(device)\n","    y_test_pred = model(x_test)\n","    y_test_pred = y_test_pred.cpu().detach().numpy()\n","    y_test= y_test.cpu().detach().numpy()\n","    mape = mean_absolute_percentage_error(y_test_pred, y_test)\n","    r2 = r2_score(y_test_pred, y_test)\n","    # print(f'r2 (higher better):    {r2:.2f}')\n","    # print(f'MAPE (smaller better): {mape:.2f}') \n","    return r2, mape, y_test_pred"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["input_size = x_train.shape[1]\n","\n","lora_size = 1\n","hidden_size = 14\n","output_size = 1\n","more_state = 2\n","\n","# Build model\n","input_dim = 1\n","hidden_dim = 8 #15\n","num_layers = 2\n","output_dim = 1\n","\n","make_imp_relu = lambda: ImplicitModel(hidden_size-1, input_size, output_size, f=CustomInf, no_D=False)\n","make_imp_triu_l = lambda: ImplicitModel(hidden_size+more_state, input_size, output_size, f=ImplicitFunctionTriu, no_D=False)\n","make_imp_triu_s = lambda: ImplicitModel(hidden_size-1, input_size, output_size, f=ImplicitFunctionTriu, no_D=False)\n","make_imp_lora = lambda: ImplicitModelLoRA(lora_size, hidden_size-1, input_size, output_size, f=CustomInf, no_D=False)\n","make_imp_rnn = lambda: ImplicitRNN(1, hidden_size+2, hidden_size+1, output_size, f=CustomInf, no_D=False)\n","make_imp_rnn_lora = lambda: ImplicitRNNLoRA(lora_size, 1, hidden_size+2, hidden_size+1, output_size, f=CustomInf, no_D=False)\n","make_my_rnn = lambda: MyRNN(1, hidden_size+7, output_size, f=CustomInf, no_D=False)\n","make_simple_rnn = lambda: SimpleRNN(1, hidden_size+2, 2, True, output_size, 'relu')\n","# make_simple_rnn = lambda: LSTM(1, hidden_size-12, 2, True, output_size)\n","# make_simple_rnn = lambda: MultiLayerLSTM(1, hidden_size-11, 2, 0.01)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["model size: 865 parameters\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  10 MSE:  0.009202291257679462\n","Epoch  20 MSE:  0.006643916945904493\n","Epoch  30 MSE:  0.005098826717585325\n","Epoch  40 MSE:  0.004547247663140297\n","Epoch  50 MSE:  0.004149706102907658\n","Epoch  60 MSE:  0.0038537313230335712\n","Epoch  70 MSE:  0.003627817379310727\n","Epoch  80 MSE:  0.0034751014318317175\n","Epoch  90 MSE:  0.0033613189589232206\n","Epoch  100 MSE:  0.0032735499553382397\n","Epoch  110 MSE:  0.0032086726278066635\n","Epoch  120 MSE:  0.003161521628499031\n","Epoch  130 MSE:  0.0031226794235408306\n","Epoch  140 MSE:  0.0030872675124555826\n","Epoch  150 MSE:  0.0030569047667086124\n","Epoch  160 MSE:  0.0030271566938608885\n","Epoch  170 MSE:  0.0029974833596497774\n","Epoch  180 MSE:  0.003006409155204892\n","Epoch  190 MSE:  0.003002670593559742\n","r2 (higher better):    0.87 +- 0.00\n","MAPE (smaller better): 4.00 +- 1.78\n","Best r2 (higher better):    0.88 at iteration 1\n","Best MAPE (smaller better): 1.88 at iteration 7\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","r2s = []\n","mapes = []\n","\n","for i in range(10):\n","    # model, lr = LSTM(input_size=input_dim, hidden_size=hidden_dim, output_size=output_dim, num_layers=num_layers, bias=True).to(device), 0.08 # new code \n","    # model, lr = OldVersionLSTM(input_dim=input_dim, hidden_dim=hidden_dim+1, output_dim=output_dim, num_layers=num_layers).to(device), 0.04 # old code\n","    # model, lr = make_my_rnn().to(device), 0.005\n","    ## model, lr = make_simple_rnn().to(device), 0.08\n","    # try RNN_implicit model\n","    # model, lr = MLP(input_size, hidden_size, output_size, nn.ReLU).to(device), 0.005\n","    # model, lr = make_imp_relu().to(device), 0.03\n","    model, lr = make_imp_lora().to(device), 0.03\n","    # model, lr = make_imp_rnn().to(device), 0.004\n","    # model, lr = make_imp_rnn_lora().to(device), 0.008\n","    model.to(device)\n","    # print(model)\n","    if i == 0:\n","        print(f'model size: {sum(p.numel() for p in model.parameters())} parameters')\n","\n","    loss_fn = torch.nn.MSELoss()\n","    optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n","    \n","    model, hist = train_model(model, x_train, y_train, optimiser, loss_fn, num_epochs=200, device=device, verbose=(i==0))\n","\n","    if i==0:    \n","        plot_hist(hist)\n","    \n","    r2, mape, y_test_pred = evaluate_model(x_train, y_train, x_test, y_test, model)\n","    r2s.append(r2)\n","    mapes.append(mape)\n","\n","print(f'r2 (higher better):    {np.mean(r2s):.2f} +- {np.std(r2s):.2f}')\n","print(f'MAPE (smaller better): {np.mean(mapes):.2f} +- {np.std(mapes):.2f}')\n","############# can calibrate size of RNN to compartible with imp_rnn\n","best_r2_index = np.argmax(r2s)\n","best_mape_index = np.argmin(mapes)\n","\n","print(f'Best r2 (higher better):    {r2s[best_r2_index]:.2f} at iteration {best_r2_index}')\n","print(f'Best MAPE (smaller better): {mapes[best_mape_index]:.2f} at iteration {best_mape_index}')"]},{"cell_type":"markdown","metadata":{},"source":["# Make Predictions\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:01:23.833456Z","iopub.status.busy":"2024-06-08T18:01:23.833031Z","iopub.status.idle":"2024-06-08T18:01:23.839742Z","shell.execute_reply":"2024-06-08T18:01:23.838941Z","shell.execute_reply.started":"2024-06-08T18:01:23.833425Z"},"trusted":true},"outputs":[],"source":["x_test = x_test.to(device)\n","y_test_pred = model(x_test)\n","y_test_pred = y_test_pred.cpu().detach().numpy()\n","y_test= y_test.cpu().detach().numpy()\n","x_train= x_train.cpu().detach().numpy()\n","x_test= x_test.cpu().detach().numpy()\n","y_train= y_train.cpu().detach().numpy()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:01:23.841158Z","iopub.status.busy":"2024-06-08T18:01:23.840833Z","iopub.status.idle":"2024-06-08T18:01:23.849109Z","shell.execute_reply":"2024-06-08T18:01:23.848148Z","shell.execute_reply.started":"2024-06-08T18:01:23.841123Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3976, 1) (3976, 1)\n","(array([-0.04454434], dtype=float32), array([-0.06129769], dtype=float32)) (array([-0.05244905], dtype=float32), array([-0.04457181], dtype=float32)) (array([-0.00175169], dtype=float32), array([-0.07204671], dtype=float32)) (array([-0.04857551], dtype=float32), array([-0.02476959], dtype=float32)) (array([-0.0083694], dtype=float32), array([-0.0434431], dtype=float32))\n"]}],"source":["print(y_test_pred.shape, y_test.shape)\n","print(*zip(y_test_pred[0:5], y_test[0:5]))"]},{"cell_type":"markdown","metadata":{},"source":["# Accuracy score"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:01:23.855492Z","iopub.status.busy":"2024-06-08T18:01:23.855162Z","iopub.status.idle":"2024-06-08T18:01:23.933350Z","shell.execute_reply":"2024-06-08T18:01:23.932333Z","shell.execute_reply.started":"2024-06-08T18:01:23.855466Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["r2 (higher better):    0.87\n","MAPE (smaller better): 3.24\n"]}],"source":["from sklearn.metrics import r2_score, mean_absolute_percentage_error\n","mape = mean_absolute_percentage_error(y_test_pred, y_test)\n","r2 = r2_score(y_test_pred, y_test)\n","print(f'r2 (higher better):    {r2:.2f}')       # refer to https://en.wikipedia.org/wiki/Coefficient_of_determination\n","print(f'MAPE (smaller better): {mape:.2f}')     # refer to https://arize.com/blog-course/mean-absolute-percentage-error-mape-what-you-need-to-know/"]},{"cell_type":"markdown","metadata":{},"source":["# Inverse transform\n","\n","to see how accurate our results are on line Graph"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:01:23.940191Z","iopub.status.busy":"2024-06-08T18:01:23.939899Z","iopub.status.idle":"2024-06-08T18:01:23.947768Z","shell.execute_reply":"2024-06-08T18:01:23.946965Z","shell.execute_reply.started":"2024-06-08T18:01:23.940166Z"},"trusted":true},"outputs":[],"source":["# Inverse transform y_test_pred and y_test\n","y_test_pred = scaler.inverse_transform(y_test_pred.reshape(-1, 1)).flatten()\n","y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n","y_train = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:01:23.949147Z","iopub.status.busy":"2024-06-08T18:01:23.948867Z","iopub.status.idle":"2024-06-08T18:01:23.957706Z","shell.execute_reply":"2024-06-08T18:01:23.956824Z","shell.execute_reply.started":"2024-06-08T18:01:23.949123Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(5964, 3976)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(y_train), len(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Results"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T18:01:23.959284Z","iopub.status.busy":"2024-06-08T18:01:23.958940Z","iopub.status.idle":"2024-06-08T18:01:24.268406Z","shell.execute_reply":"2024-06-08T18:01:24.267526Z","shell.execute_reply.started":"2024-06-08T18:01:23.959251Z"},"trusted":true},"outputs":[],"source":["# %matplotlib inline\n","import matplotlib.patches as patches\n","\n","# Assuming y_train, y_test_pred, and y_test are already defined\n","# Create the plot\n","plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n","\n","# Plot y_train with a different color\n","plt.plot(range(len(y_train)), y_train, label='TrainData', color='blue')  \n","\n","# Plot y_test_pred and y_test with different colors\n","plt.plot(range(len(y_train), len(y_train) + len(y_test_pred)), y_test_pred, label='Predicted', color='red')\n","plt.plot(range(len(y_train), len(y_train) + len(y_test)), y_test, label='ValidationData', color='lightgreen')\n","\n","# Set the y-axis limits based on the minimum and maximum values of both arrays\n","plt.ylim(min(y_train.min(), y_test_pred.min(), y_test.min()), max(y_train.max(), y_test_pred.max(), y_test.max()))\n","\n","# Set the x-axis limits\n","plt.xlim(0, len(y_train) + len(y_test))\n","\n","# Add labels and title\n","plt.xlabel('X-axis')\n","# plt.ylabel(fea_name)\n","\n","# Display the legend\n","plt.legend()\n","\n","# Add a square around the y_t\n","ax = plt.gca()\n","rect = patches.Rectangle((len(y_train), min(y_test_pred.min(), y_test.min())), len(y_test_pred), \n","                         max(y_test_pred.max(), y_test.max()) - min(y_test_pred.min(), y_test.min()), \n","                         linewidth=2, edgecolor='black', facecolor='none', linestyle='--')\n","ax.add_patch(rect)\n","# Show the plot\n","plt.grid(True)  # Add a grid if desired\n","plt.show()\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# %matplotlib inline\n","import matplotlib.patches as patches\n","start = 1000\n","end = start + 250\n","\n","# Assuming y_train, y_test_pred, and y_test are already defined\n","# Create the plot\n","plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n","\n","\n","# Plot y_test_pred and y_test with different colors\n","plt.plot(range(len(y_test_pred[start:end])), y_test_pred[start:end], label='Predicted', color='red')\n","plt.plot(range(len(y_test[start:end])), y_test[start:end], label='ValidationData', color='lightgreen')\n","\n","# Set the y-axis limits based on the minimum and maximum values of both arrays\n","plt.ylim(min(y_test_pred[start:end].min(), y_test[start:end].min()), max(y_test_pred[start:end].max(), y_test[start:end].max()))\n","\n","# Set the x-axis limits\n","plt.xlim(0, len(y_test[start:end]))\n","\n","# Add labels and title\n","plt.xlabel('X-axis')\n","# plt.ylabel(fea_name)\n","\n","# Display the legend\n","plt.legend()\n","\n","# # Add a square around the y_t\n","# ax = plt.gca()\n","# rect = patches.Rectangle((len(y_train), min(y_test_pred.min(), y_test.min())), len(y_test_pred), \n","#                          max(y_test_pred.max(), y_test.max()) - min(y_test_pred.min(), y_test.min()), \n","#                          linewidth=2, edgecolor='black', facecolor='none', linestyle='--')\n","# ax.add_patch(rect)\n","# # Show the plot\n","plt.title(\"Predicted vs. Validation Data - ImplicitRNN LORA\")\n","plt.grid(True)  # Add a grid if desired\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["- chạy nốt các thí nghiệm với model khác\n","- tune dataset để thấy rõ khác biệt giữ idl với edl\n","- hoàn thành bảng\n","- tiếp earthquake\n","\n","only >=, <=, =\n","no < or > for LP problem\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5081145,"sourceId":8511889,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
